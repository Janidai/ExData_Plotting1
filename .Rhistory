sqldf("select AGEP where unique from acs")
sqldf("select distinct AGEP from acs")
identical(subset1,sqldf("select distinct AGEP from acs"))
str(unique(acs$AGEP))
str(sqldf("select distinct AGEP from acs"))
install.packages('httr')
library('httr')
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html <- GET(url)
html
html[10]
html[,10]
str(htl)
str(html)
html$content
content <- content(html,as="text")
?content
content
content <- content(html,as="parsed")
install.packages('XML')
library('XML')
content <- content(html,as="text")
content
parsed_content(content)
parsed_content(content, as = 'parsed')
parsed(content, as = 'parsed')
content
content <- content(html,type = "text/xml")
install.packages('XML')
install.packages('XML')
content <- content(html,type = "text/xml")
content
library('XML')
parsed_html <- htmlParse(content, asText = TRUE)
parsed_html
str(parsed_html)
parsed_html[1]
parsed_html[1,]
parsed_html
nchar(parsed_html)
con = url(url)
htmlCode = readLines(con)
htmlCode
htmlCode[]10
htmlCode[10]
close(con)
htmlCode[10] htmlCode[20] htmlCode[30] htmlCode[100]
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
con = url(url)
htmlCode = readLines(con)
close(con)
htmlCode[10]; htmlCode[20]; htmlCode[30]; htmlCode[100]
length(htmlCode[10])
as.Text(htmlCode[10])
as.character(htmlCode[10])
lenght(as.character(htmlCode[10]))
length(as.character(htmlCode[10]))
nchar(htmlCode[10])
typeof(htmlCode[10])
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
?download.file
download.file(url5,"/tmp/data5.csv",method = "wget")
url5 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(url5,"/tmp/data5.csv",method = "wget")
data5 <- read.delim("/tmp/data5.csv")
head(data5)
str(data5)
data5 <- read.delim2("/tmp/data5.csv")
str(data5)
?read.delim
data5 <- read.delim2("/tmp/data5.csv",header = TRUE)
str(data5)
dim(data5)
data5 <- read.delim("/tmp/data5.csv",header = TRUE)
dim(data5)
dim(data5)
dec = ".", fill = TRUE, comment.char = "", ...)
data5 <- read.delim(file, header = TRUE, sep = "\t", quote = "\"",
data5 <- read.delim(file, header = TRUE, sep = "\t", quote = "\"",
dec = ".", fill = TRUE, comment.char = "", ...)
data5 <- read.delim(file, header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "", ...)
data5 <- read.delim(file, header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
data5 <- read.delim(data5, header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
data5 <- read.delim("/tmp/data5.csv", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
dim(data5)
dim(data5)
download.file(url5,"/tmp/data5.foo",method = "wget")
data5 <- read.delim("/tmp/data5.foo", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
data5
str(data5)
data5 <- read.delim("/tmp/data5.for", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
url5 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(url5,"/tmp/data5.for",method = "wget")
data5 <- read.delim("/tmp/data5.for", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
data5
str(data5)
data5 <- read.delim2("/tmp/data5.for", header = TRUE, sep = "\t", quote = "\"", dec = ".", fill = TRUE, comment.char = "")
str(data5)
data5 <- read.delim2("/tmp/data5.for")
str(data5)
data5 <- read.fwf("/tmp/data5.for",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4)
str(data5)
str(data5)
download.file(url5,"/tmp/data5.for",method = "wget")
data5 <- read.fwf("/tmp/data5.for",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4)
data5 <- read.fwf("/tmp/data5.for",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
data5 <- read.fwf("/tmp/data5.for",skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
str(data5)
sum(data5$V4)
ube <- function(x, n) {
x^3
}
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
x <- Sys.Date()
x
typeof(x)
x <- Sys.tate()
time <- Sys.time()
typeof(time)
as.POSIXct(time)
time2 <- as.POSIXct(time)
time2$
names(time2)
time2 <- as.POSIXlt(time)
names(time2)
time2
names(unclass(time2)
)
class(time2)
typeof(time2)
time2$sec
weekdays(time2)
weekdays(time)
time2
time3 <- as.POSIXlt(Sys.time())
time3 > time2
time3$isdt
time3$isdst
time3$zone
time3$gmtoff
tiempo <- "January 10, 2012 10:40"
strptime(tiempo, %B %d)
strptime(tiempo, %B %d, %Y %H:%M)
Sys.setenv(LANG = "en")
strptime(tiempo, %B %d, %Y %H:%M)
defaults write org.R-project.R force.LANG en_US.UTF-8
defaults write org.R-project.R force.LANG en_US.UTF-8
help(Startup)
Sys.getenv("LANG")
Sys.setenv(LANG = "en_US.UTF-8")
Sys.getenv("LANG")
q()
Sys.getenv("LANG")
Sys.setenv(LANG = "en_US.UTF-8")
Sys.getenv("LANG")
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
p <- function(x){x+x}
p(2)
makeVector(vec)
vec <- makeVector()
vec$set(2)
vec$get
vec$get()
a <- makeVector(c(1,2,3,4))
a$get()
a$getmean()
cachemean(a)
a$getmean()  # this is only to show you that the mean has been stored and does not affect anything
cachemean(a)
a$set(c(10,20,30,40))
a$getmean()
cachemean(a)
cachemean(a)
a$get()
a$setmean(0)  # do NOT call setmean() directly despite it being accessible for the reason you will see next
a$getmean()
a$get()
cachemean(a)
amatrix = makeCacheMatrix(matrix(c(1,2,3,4), nrow=2, ncol=2))
source("cachematrix.R")
makeCacheMatrix <- function(matrix = matrix()) {
# store inverse value
inverse <- NULL
# set the original matrix and reset inverse
set <- function(y) {
matrix <<- y
inverse <<- NULL
}
# get the original matrix
get <- function() matrix
# set inverse value
set_inverse <- function(inv) inverse <<- inv
# get inverse value
get_inverse <- function() inverse
# Returns a list of the 4 functions, this is the special "matrix"
list(set = set, get = get,
set_inverse = set_inverse,
get_inverse = get_inverse)
}
## This function computes the inverse of the special "matrix" returned by
## makeCacheMatrix above. If the inverse has already been calculated (and
## the matrix has not changed), then the cachesolve should retrieve the
## inverse from the cache.
cacheSolve <- function(special_matrix, ...) {
inverse <- special_matrix$get_inverse()
if(!is.null(inverse)) {
message("getting cached data")
return(inverse)
}
data <- special_matrix$get()
inverse <- solve(data, ...)
special_matrix$set_inverse(inverse)
inverse
}
amatrix = makeCacheMatrix(matrix(c(1,2,3,4), nrow=2, ncol=2))
amatrix$get()         # Returns original matrix
cacheSolve(amatrix)   # Computes, caches, and returns    matrix inverse
amatrix$get_inverse()  # Returns matrix inverse
cacheSolve(amatrix)   # Returns cached matrix inverse using previously computed matrix inverse
amatrix$set(matrix(c(0,5,99,66), nrow=2, ncol=2)) # Modify existing matrix
cacheSolve(amatrix)   # Computes, caches, and returns new matrix inverse
amatrix$get()         # Returns matrix
amatrix$getinverse()  # Returns matrix inverse
amatrix$get_inverse()  # Returns matrix inverse
library('swirl')
install_from_swirl("Getting and Cleaning Data")
swirl()
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head()
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
tbl_df
cran
?manip
select(cran, ip_id, package, country)
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran,r_version == "3.1.1", country == "US")
?Comparison
filter(cran,r_version <= "3.1.1", country == "IN")
filter(cran,r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country =="IN")
filter(cran,size>100500,r_os == "linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
cran2 <- select(cran,size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id)
)
arrange(cran2,package,ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3 <- select(cran, ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2 ^ 10)
mutate(cran3, correct_size = size + 1000)
summarize(cran,avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
summarize(by_package,mean(size))
submit
submit()
pack_sum
quantile(pack_sum$count,probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
head(top_counts,20)
arragnge(top_counts,desc(count))
arrange(top_counts,desc(count))
quantile(pack_sum$unique,probs = 0.99)
top_unique <- filter(pack_sum,unique > 465)
top_unique
arrange(top_unique, desc(unique))
submit()
submit()
submit()
submit()
print
submit()
submit()
cran %>%
select(ip_id,country,package,size) %>%
print()
submit()
submit()
submit()
submit()
library(datasets)
data(iris)
?iris
head(iris)
str(iris)
summary(iris)
library(dyplr)
library(dplyr)
iris <- tbl_df(iris)
iris
print(iris)
select(iris,Species==virginica)
filter(iris,Species==virginica)
filter(iris,Species=="virginica")
filter(iris,Species=="virginica") %>% summary(mean())
filter(iris,Species=="virginica") %>% summary(mean
)
iris[["Sepal.length"]]
iris[["Sepal.Length"]]
mean(iris[["Sepal.Length"]])
species <- group_by(iris,Species)
species
mean <- summarise(species,mean)
mean <- summarise(species,mean(Sepal.Length))
mean
library(datasets)
library(dplyr)
data(iris)
iris <- tbl_df(iris)
species <- group_by(iris,Species)
means <- summarize(iris,mean(Sepal.Length))
means
means <- summarize(species,mean(Sepal.Length))
means
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 2, mean)
apply(iris[, 1:4], 1, mean)
colMeans(iris)
apply(iris, 1, mean)
summarize(iris,mean(1:5))
summarize(iris,mean(1))
summarize(iris,mean(Speal.Lenth))
summarize(iris,mean("Speal.Lenth"))
summarise(iris,mean(Sepal.Length))
summarise(iris,mean(Sepal.Length),mean(Sepal.Width),mean(Petal.Length),mean(Petal.Width))
apply(iris[, 1:4], 2, mean)
summary(iris)
library(datasets)
data(mtcars)
?mtcars
# Continuing with the 'iris' dataset from the previous Question, what R code returns a vector of the means of the variables 'Sepal.Length', 'Sepal.Width', 'Petal.Length', and 'Petal.Width'?
sapply(split(mtcars$mpg, mtcars$cyl), mean)
lapply(mtcars, mean)
mean(mtcars$mpg, mtcars$cyl)
apply(mtcars, 2, mean)
mtcars <- tbl_df(mtcars)
summarize(group_by(mtcars,cyl),ave(mtcars.mpg))
summarize(group_by(mtcars,cyl),ave("mtcars.mpg"))
cyl <- group_by(mtcars,cyl)
cyl
summarise(cyl,mean(cyl.mpg))
summarise(cyl,mean("cyl.mpg"))
summarise(cyl,mean = mean("cyl.mpg"))
summarise(cyl,mean = mean(cyl.mpg))
summarise(cyl,mean = mean(mpg))
library(datasets)
data(mtcars)
str(mtcars)
library(dplyr)
mtcars <- tbl_df(mtcars)
mtcars %>% summarise(mean(hp))
str(mtcars)
summarize(mtcars)
hp_mean <- mtcars %>% summarise(mean(hp))
hp_mean
as.integer(hp_meant)
as.integer(hp_mean)
as.double(hp_mean)
data_mtcars <- data(mtcars)
summarize(data_mtcars)
summarise(data_mtcars)
summary(data_mtcars)
summary(mtcars)
mtcars %>% filter(cyl == 4) %>% summarise(mean(hp))
mtcars %>% filter(cyl == 4)
mtcars %>% filter(cyl == 4) %>% summarise(mean(hp))
hp_mean <- mtcars %>% filter(cyl == 4) %>% summarise(mean(hp))
hp_mean <- as.double(hp_mean)
hp_mean_4 <- mtcars %>% filter(cyl == 4) %>% summarise(mean(hp))
hp_mean_4 <- as.double(hp_mean_4)
hp_mean_8 <- mtcars %>% filter(cyl == 8) %>% summarise(mean(hp))
hp_mean_8 <- as.double(hp_mean_8)
abs(hp_mean_4,hp_mean_8)
abs(hp_mean_4-hp_mean_8)
debug(ls)
ls
ls()
q
quit()
exit
exit()
q
q()
a
setwd("~/Repos/ExData_Plotting1")
data <- read.table("./data/household_power_consumption.txt",
header = TRUE,
sep=";",
na.strings = "?")
data <- subset(data, Date == "1/2/2007" | Date == "2/2/2007")
data$Date <- as.Date(data$Date,format = "%d/%m/%Y")
hist(data$Global_active_power,
col = "red",
labels = "Global Active Power (kilowatts)",
title = "Global Active Power")
hist(data$Global_active_power,
col = "red",
title = "Global Active Power")
hist(data$Global_active_power,
col = "red")
?hist
hist(data$Global_active_power,
col = "red", main = "Title")
hist(data$Global_active_power,
col = "red",
main = "Global Active Power",
xlab = "Global Active Power (kilowatts)")
dev.copy(png, "./plot1.R")
dev.copy(png, "./plot1.png")
dev.off()
setwd("~/Repos/ExData_Plotting1/")
dev.copy(png, "./plot1.png")
dev.off()
data2 <- data
time <- paste(data2$Date, data2$Time, sep = " ")
time <- as.Date(time, format = "%Y-%m-%d %H:%M:%S")
time <- paste(data2$Date, data2$Time, sep = " ")
time <- as.Date(time, format = "%Y-%m-%d")
time <- paste(data2$Date, data2$Time, sep = " ")
time <- as.Date(time[], format = "%Y-%m-%d %H:%M:%S")
time <- paste(data2$Date, data2$Time, sep = " ")
time <- as.Date(time, format = "%Y-%m-%d %H:%M:%S")
time <- paste(data2$Date, data2$Time, sep = " ")
time
time <- as.Date(time)
comp_time <- paste(data2$Date, data2$Time, sep = " ")
comp_time <- as.Date(time)
time <- paste(data2$Date, data2$Time, sep = " ")
strptime(time,format = "%Y-%m-%d %H:%M:%S")
data2$Date <- strptime(time,format = "%Y-%m-%d %H:%M:%S")
str(data2)
within(data2,plot(Global_active_power ~ Date))
hist(data2$Date)
plot(data$Global_active_power, data2$Date)
plot(data2$Date,data2$Global_active_power)
plot(data2$Date,data2$Global_active_power, type = "n")
lines(data2$Date,data2$Global_active_power)
